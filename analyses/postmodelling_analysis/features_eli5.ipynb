{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance analysis with ELI5\n",
    "\n",
    "Using ELI5, this script allows you to plot feature importance for models, as well as for individual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import eli5\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "sys.path.append('../../src/utils/')\n",
    "sys.path.append('../../src/models/')\n",
    "sys.path.append('../../src/features/')\n",
    "sys.path.append('../../src/store/')\n",
    "sys.path.append('../../src/dataproc/')\n",
    "\n",
    "from persist import load, save\n",
    "from load_config import *\n",
    "from SQLConn import SQLConn\n",
    "from create_data_sample import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_paths_env = load_local_paths('../../src/pipeline/local_paths.yaml')\n",
    "env = load_psql_env(local_paths_env['pgpass_path'])\n",
    "prod_config = load_config('../../src/prod/prod_config.yaml', append_static=False)\n",
    "connection = SQLConn(env)\n",
    "\n",
    "# pull data from database\n",
    "connection.open()\n",
    "X_train, X_test, y_train, y_test = sample(ignition=prod_config, connection=connection,\n",
    "                                              local_features_path=local_paths_env['store_features'])\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store model and file names\n",
    "model_names = []\n",
    "file_names = []\n",
    "\n",
    "for file in os.listdir(local_paths_env['store_production_models']):\n",
    "    mod = ''.join([c for c in file if c.isupper()])\n",
    "    model_names.append(mod)\n",
    "    file_names.append(file.rstrip('.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving top 1000 features for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_groups = {}\n",
    "\n",
    "for i, mod in enumerate(model_names):\n",
    "    if not mod in features_groups.keys():\n",
    "        print(file_names[i])\n",
    "        print(mod)\n",
    "        \n",
    "        # load model\n",
    "        model = load(local_paths_env['store_production_models'], file_names[i])\n",
    "        \n",
    "        # check if it has a vectorizer - rest of the notebook assumes this is the case\n",
    "        if hasattr(model, 'vectorizer'):\n",
    "            clf = model.models[model_names[i].lower()]\n",
    "\n",
    "            # not all models have the same number of weights - try a high number\n",
    "            # and decreaase if that fails\n",
    "            try:\n",
    "                weights = eli5.explain_weights(clf, vec=model.vectorizer, top=1000, target_names=[0,1])\n",
    "            except:\n",
    "                try:\n",
    "                    weights = eli5.explain_weights(clf, vec=model.vectorizer, target_names=[0,1])\n",
    "\n",
    "                except:\n",
    "                    try:\n",
    "                        weights = eli5.explain_weights(clf, vec=model.vectorizer, top=10, target_names=[0,1])\n",
    "                    except:\n",
    "                        weights = eli5.explain_weights(clf, vec=model.vectorizer, top=5, target_names=[0,1])\n",
    "\n",
    "            features_list = eli5.formatters.as_dataframe.format_as_dataframe(weights)['feature'].tolist()\n",
    "            features_groups[model_names[i]] = features_list\n",
    "        else:\n",
    "            print(\"This model has no vectorizer.\")    \n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in features_groups.items() ]))\n",
    "features_data.to_csv('features_data.csv')\n",
    "features_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing individual models and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index determines which group's model is selected\n",
    "i = 1\n",
    "\n",
    "# load model\n",
    "model = load(local_paths_env['store_production_models'], file_names[i])\n",
    "\n",
    "# check if it has a vectorizer - rest of the notebook assumes this is the case\n",
    "if hasattr(model, 'vectorizer'):\n",
    "    clf = model.models[model_names[i].lower()]\n",
    "else:\n",
    "    print(\"This model has no vectorizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_[:,75000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing weights for one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights for class (overall)\n",
    "eli5.explain_weights(clf, vec=model.vectorizer, top=6, target_names=[0,1])\n",
    "np.count_nonzero(clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing weights for one paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a paper randomly belonging to the class of the model currently loaded\n",
    "classdata = X_test[y_test[model_names[i].lower()]]\n",
    "n = random.randint(0, len(classdata))\n",
    "testpaper = classdata[model.tokens_col].iloc[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the prediction for a paper\n",
    "print(model_names[i])\n",
    "eli5.show_prediction(clf, testpaper, vec=model.vectorizer, target_names=[True, False])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
